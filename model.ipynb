{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3069915c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews shape: (701528, 10)\n",
      "Meta shape: (112590, 14)\n",
      "Review columns: ['rating', 'title', 'text', 'images', 'asin', 'parent_asin', 'user_id', 'timestamp', 'helpful_vote', 'verified_purchase']\n",
      "Meta columns: ['main_category', 'title', 'average_rating', 'rating_number', 'features', 'description', 'price', 'images', 'videos', 'store', 'categories', 'details', 'parent_asin', 'bought_together']\n",
      "Merging on key: parent_asin\n",
      "Merged shape: (701528, 24)\n",
      "Train size: (561222, 10) Test size: (140306, 10)\n",
      "Fitting model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emmalin/anaconda3/envs/agential/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.16      0.26     13312\n",
      "           1       0.92      0.99      0.95    126994\n",
      "\n",
      "    accuracy                           0.92    140306\n",
      "   macro avg       0.83      0.58      0.61    140306\n",
      "weighted avg       0.90      0.92      0.89    140306\n",
      "\n",
      "ROC-AUC: 0.8084673208838\n",
      "Confusion matrix:\n",
      " [[  2131  11181]\n",
      " [   720 126274]]\n",
      "\n",
      "Example prediction: {'predicted_verified_flag': 1, 'probability_verified': 0.8069951244507537}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gzip\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "\n",
    "\n",
    "def load_jsonl_gz(path, limit=None):\n",
    "    \"\"\"Load a .jsonl.gz file into a pandas DataFrame.\"\"\"\n",
    "    path = os.path.expanduser(path)\n",
    "    rows = []\n",
    "    with gzip.open(path, 'rt', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if limit is not None and i >= limit:\n",
    "                break\n",
    "            try:\n",
    "                rows.append(json.loads(line))\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# load data \n",
    "\n",
    "reviews_path = '~/Downloads/amazon_vp/All_Beauty.jsonl.gz'\n",
    "meta_path    = '~/Downloads/amazon_vp/meta_All_Beauty.jsonl.gz'\n",
    "\n",
    "df_reviews = load_jsonl_gz(reviews_path, limit=None)\n",
    "df_meta    = load_jsonl_gz(meta_path,    limit=None)\n",
    "\n",
    "print(\"Reviews shape:\", df_reviews.shape)\n",
    "print(\"Meta shape:\", df_meta.shape)\n",
    "print(\"Review columns:\", df_reviews.columns.tolist())\n",
    "print(\"Meta columns:\", df_meta.columns.tolist())\n",
    "\n",
    "\n",
    "# CLEANING DATA\n",
    "\n",
    "# 'helpful_vote' vs 'helpful_votes'\n",
    "if 'helpful_votes' not in df_reviews.columns and 'helpful_vote' in df_reviews.columns:\n",
    "    df_reviews['helpful_votes'] = df_reviews['helpful_vote']\n",
    "\n",
    "# 'sort_timestamp' vs 'timestamp'\n",
    "if 'sort_timestamp' in df_reviews.columns and 'timestamp' not in df_reviews.columns:\n",
    "    df_reviews['timestamp'] = df_reviews['sort_timestamp']\n",
    "\n",
    "# check verified_purchase exists\n",
    "if 'verified_purchase' not in df_reviews.columns:\n",
    "    raise ValueError(\"verified_purchase column not found in review data.\")\n",
    "\n",
    "# parent_asin vs asin\n",
    "join_key = 'asin'\n",
    "if 'parent_asin' in df_reviews.columns and 'parent_asin' in df_meta.columns:\n",
    "    join_key = 'parent_asin'\n",
    "\n",
    "print(\"Merging on key:\", join_key)\n",
    "\n",
    "df = df_reviews.merge(df_meta, on=join_key, how='left', suffixes=('_review', '_product'))\n",
    "\n",
    "df = df.dropna(subset=['text', 'verified_purchase'])\n",
    "\n",
    "print(\"Merged shape:\", df.shape)\n",
    "\n",
    "\n",
    "# CHECKING FEATURES\n",
    "\n",
    "df['review_text']  = df['text'].fillna('')\n",
    "df['review_title'] = df.get('title_review', df.get('title', '')).fillna('')\n",
    "\n",
    "# title + text\n",
    "df['combined_text'] = (df['review_title'] + ' ' + df['review_text']).str.strip()\n",
    "\n",
    "# review length (in words)\n",
    "df['review_length'] = df['review_text'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# binary: has images in review\n",
    "if 'images_review' in df.columns:\n",
    "    df['has_images'] = df['images_review'].apply(lambda x: int(isinstance(x, list) and len(x) > 0))\n",
    "elif 'images' in df.columns:\n",
    "    df['has_images'] = df['images'].apply(lambda x: int(isinstance(x, list) and len(x) > 0))\n",
    "else:\n",
    "    df['has_images'] = 0\n",
    "\n",
    "# helpful votes\n",
    "if 'helpful_votes' in df.columns:\n",
    "    df['helpful_votes'] = df['helpful_votes'].fillna(0).astype(float)\n",
    "else:\n",
    "    df['helpful_votes'] = 0.0\n",
    "\n",
    "# ratings\n",
    "if 'rating' in df.columns:\n",
    "    df['rating'] = df['rating'].astype(float)\n",
    "else:\n",
    "    df['rating'] = np.nan\n",
    "\n",
    "# product features (num)\n",
    "df['price']          = df.get('price', np.nan).astype(float)\n",
    "df['average_rating'] = df.get('average_rating', np.nan).astype(float)\n",
    "df['rating_number']  = df.get('rating_number', np.nan).astype(float)\n",
    "\n",
    "# product features (cat)\n",
    "df['main_category']  = df.get('main_category', 'Unknown').fillna('Unknown')\n",
    "df['store']          = df.get('store', 'Unknown').fillna('Unknown')\n",
    "\n",
    "y = df['verified_purchase'].astype(int)\n",
    "\n",
    "text_col = 'combined_text'\n",
    "numeric_features = [\n",
    "    'rating',\n",
    "    'helpful_votes',\n",
    "    'review_length',\n",
    "    'has_images',\n",
    "    'price',\n",
    "    'average_rating',\n",
    "    'rating_number',\n",
    "]\n",
    "categorical_features = [\n",
    "    'main_category',\n",
    "    'store',\n",
    "]\n",
    "\n",
    "# missing vals\n",
    "for col in numeric_features:\n",
    "    if col not in df.columns:\n",
    "        df[col] = np.nan\n",
    "df[numeric_features] = df[numeric_features].fillna(df[numeric_features].median())\n",
    "\n",
    "X = df[[text_col] + numeric_features + categorical_features]\n",
    "\n",
    "\n",
    "# split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train size:\", X_train.shape, \"Test size:\", X_test.shape)\n",
    "\n",
    "\n",
    "# text + numeric + categorical -> logistic regression\n",
    "\n",
    "text_transformer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words='english'\n",
    ")\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text', text_transformer, text_col),\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "clf = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    solver='saga',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocess', preprocess),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# TRAINING\n",
    "print(\"Fitting model...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# EVAL\n",
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "\n",
    "\n",
    "# predictor new rev\n",
    "def predict_verified(\n",
    "    review_text,\n",
    "    review_title=\"\",\n",
    "    rating=5.0,\n",
    "    helpful_votes=0,\n",
    "    images_count=0,\n",
    "    price=np.nan,\n",
    "    average_rating=np.nan,\n",
    "    rating_number=np.nan,\n",
    "    main_category=\"All Beauty\",\n",
    "    store=\"Unknown\"\n",
    "):\n",
    "    # is review from verified purchase? \n",
    "    \n",
    "    has_images = int(images_count > 0)\n",
    "    review_length = len(str(review_text).split())\n",
    "\n",
    "    data = pd.DataFrame([{\n",
    "        'combined_text': (review_title + \" \" + review_text).strip(),\n",
    "        'rating': float(rating),\n",
    "        'helpful_votes': float(helpful_votes),\n",
    "        'review_length': review_length,\n",
    "        'has_images': has_images,\n",
    "        'price': price,\n",
    "        'average_rating': average_rating,\n",
    "        'rating_number': rating_number,\n",
    "        'main_category': main_category,\n",
    "        'store': store,\n",
    "    }])\n",
    "\n",
    "    proba = model.predict_proba(data)[0, 1]\n",
    "    pred = model.predict(data)[0]\n",
    "\n",
    "    return {\n",
    "        'predicted_verified_flag': int(pred),\n",
    "        'probability_verified': float(proba)\n",
    "    }\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "example = predict_verified(\n",
    "    review_text=\"This lotion arrived on time and smells amazing. I've been using it for two weeks and I really notice softer skin.\",\n",
    "    review_title=\"Works pretty well\",\n",
    "    rating=4,\n",
    "    helpful_votes=3,\n",
    "    images_count=1,\n",
    "    price=12.99,\n",
    "    average_rating=4.2,\n",
    "    rating_number=120,\n",
    "    main_category=\"All Beauty\",\n",
    "    store=\"SomeBrand\"\n",
    ")\n",
    "\n",
    "print(\"\\nExample prediction:\", example)\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4421cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     634969\n",
       "False     66559\n",
       "Name: verified_purchase, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['verified_purchase'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6e8f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting balanced model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emmalin/anaconda3/envs/agential/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Balanced Model (Threshold 0.5) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.68      0.40     13312\n",
      "           1       0.96      0.82      0.89    126994\n",
      "\n",
      "    accuracy                           0.81    140306\n",
      "   macro avg       0.62      0.75      0.64    140306\n",
      "weighted avg       0.90      0.81      0.84    140306\n",
      "\n",
      "ROC-AUC: 0.8235557190968517\n",
      "Confusion matrix:\n",
      " [[  9066   4246]\n",
      " [ 22694 104300]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "\n",
    "#    - 'text', 'title_review' or 'title'\n",
    "#    - 'verified_purchase'\n",
    "#    - 'rating', 'helpful_votes', 'price',\n",
    "#      'average_rating', 'rating_number',\n",
    "#      'main_category', 'store'\n",
    "\n",
    "# text\n",
    "df['review_text']  = df['text'].fillna('')\n",
    "df['review_title'] = df.get('title_review', df.get('title', '')).fillna('')\n",
    "df['combined_text'] = (df['review_title'] + ' ' + df['review_text']).str.strip()\n",
    "\n",
    "# numeric features\n",
    "df['review_length'] = df['review_text'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "if 'images_review' in df.columns:\n",
    "    df['has_images'] = df['images_review'].apply(lambda x: int(isinstance(x, list) and len(x) > 0))\n",
    "elif 'images' in df.columns:\n",
    "    df['has_images'] = df['images'].apply(lambda x: int(isinstance(x, list) and len(x) > 0))\n",
    "else:\n",
    "    df['has_images'] = 0\n",
    "\n",
    "df['helpful_votes'] = df.get('helpful_votes', 0).fillna(0).astype(float)\n",
    "df['rating']        = df.get('rating', np.nan).astype(float)\n",
    "df['price']         = df.get('price', np.nan).astype(float)\n",
    "df['average_rating']= df.get('average_rating', np.nan).astype(float)\n",
    "df['rating_number'] = df.get('rating_number', np.nan).astype(float)\n",
    "\n",
    "df['main_category'] = df.get('main_category', 'Unknown').fillna('Unknown')\n",
    "df['store']         = df.get('store', 'Unknown').fillna('Unknown')\n",
    "\n",
    "y = df['verified_purchase'].astype(int)\n",
    "\n",
    "text_col = 'combined_text'\n",
    "numeric_features = [\n",
    "    'rating',\n",
    "    'helpful_votes',\n",
    "    'review_length',\n",
    "    'has_images',\n",
    "    'price',\n",
    "    'average_rating',\n",
    "    'rating_number',\n",
    "]\n",
    "categorical_features = ['main_category', 'store']\n",
    "\n",
    "# rep na with median\n",
    "df[numeric_features] = df[numeric_features].fillna(df[numeric_features].median())\n",
    "\n",
    "X = df[[text_col] + numeric_features + categorical_features]\n",
    "\n",
    "# train/test stratified split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "text_transformer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words='english'\n",
    ")\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text', text_transformer, text_col),\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# logistic reg \n",
    "clf = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    solver='saga',\n",
    "    n_jobs=-1,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocess', preprocess),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "print(\"Fitting balanced model...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# default thres 0.5\n",
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n=== Balanced Model (Threshold 0.5) ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e5a9bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.10 → class 0 (unverified) F1 = 0.288, prec=0.714, rec=0.180\n",
      "Threshold 0.15 → class 0 (unverified) F1 = 0.367, prec=0.644, rec=0.257\n",
      "Threshold 0.20 → class 0 (unverified) F1 = 0.419, prec=0.579, rec=0.328\n",
      "Threshold 0.25 → class 0 (unverified) F1 = 0.450, prec=0.522, rec=0.395\n",
      "Threshold 0.30 → class 0 (unverified) F1 = 0.466, prec=0.471, rec=0.461\n",
      "Threshold 0.35 → class 0 (unverified) F1 = 0.466, prec=0.422, rec=0.520\n",
      "Threshold 0.40 → class 0 (unverified) F1 = 0.452, prec=0.373, rec=0.574\n",
      "Threshold 0.45 → class 0 (unverified) F1 = 0.431, prec=0.328, rec=0.628\n",
      "Threshold 0.50 → class 0 (unverified) F1 = 0.402, prec=0.285, rec=0.681\n",
      "Threshold 0.55 → class 0 (unverified) F1 = 0.370, prec=0.247, rec=0.737\n",
      "Threshold 0.60 → class 0 (unverified) F1 = 0.333, prec=0.211, rec=0.786\n",
      "Threshold 0.65 → class 0 (unverified) F1 = 0.297, prec=0.180, rec=0.838\n",
      "Threshold 0.70 → class 0 (unverified) F1 = 0.263, prec=0.155, rec=0.886\n",
      "Threshold 0.75 → class 0 (unverified) F1 = 0.235, prec=0.134, rec=0.928\n",
      "Threshold 0.80 → class 0 (unverified) F1 = 0.210, prec=0.118, rec=0.958\n",
      "Threshold 0.85 → class 0 (unverified) F1 = 0.193, prec=0.107, rec=0.978\n",
      "Threshold 0.90 → class 0 (unverified) F1 = 0.181, prec=0.100, rec=0.992\n",
      "\n",
      "Best threshold for unverified:\n",
      "t = 0.30, prec=0.471, rec=0.461, f1=0.466\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "def find_best_threshold_for_unverified(y_true, y_proba, verbose=True):\n",
    "    \"\"\"\n",
    "    y_proba = P(verified = 1)\n",
    "    We convert to \"unverified\" by thresholding 1 - y_proba.\n",
    "    \"\"\"\n",
    "    best_t = 0.5\n",
    "    best_f1 = -1\n",
    "    best_stats = None\n",
    "\n",
    "    # thresholds over verified probability\n",
    "    thresholds = np.linspace(0.1, 0.9, 17)\n",
    "\n",
    "    for t in thresholds:\n",
    "        # predict verified=1 if proba >= t, else 0\n",
    "        y_pred = (y_proba >= t).astype(int)\n",
    "\n",
    "        # compute precision/recall/f1 per class\n",
    "        prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "            y_true, y_pred, average=None, labels=[0, 1]\n",
    "        )\n",
    "        # index 0 = class 0 (unverified)\n",
    "        f1_unverified = f1[0]\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Threshold {t:.2f} → class 0 (unverified) F1 = {f1_unverified:.3f}, \"\n",
    "                  f\"prec={prec[0]:.3f}, rec={rec[0]:.3f}\")\n",
    "\n",
    "        if f1_unverified > best_f1:\n",
    "            best_f1 = f1_unverified\n",
    "            best_t = t\n",
    "            best_stats = (prec[0], rec[0], f1_unverified)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\nBest threshold for unverified:\")\n",
    "        print(f\"t = {best_t:.2f}, prec={best_stats[0]:.3f}, rec={best_stats[1]:.3f}, f1={best_stats[2]:.3f}\")\n",
    "\n",
    "    return best_t, best_stats\n",
    "\n",
    "best_t, best_stats = find_best_threshold_for_unverified(y_test, y_proba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f81ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_suspicious_reviews(df_reviews_raw, model, threshold_verified=0.7, top_n=50):\n",
    "    \"\"\"\n",
    "    df_reviews_raw: original df with all the columns before split\n",
    "    model: fitted sklearn Pipeline\n",
    "    threshold_verified: reviews with P(verified) < this are suspicious\n",
    "    top_n: return top N most suspicious reviews (lowest P(verified))\n",
    "    \"\"\"\n",
    "    # recompute features\n",
    "    tmp = df_reviews_raw.copy()\n",
    "\n",
    "    tmp['review_text']  = tmp['text'].fillna('')\n",
    "    tmp['review_title'] = tmp.get('title_review', tmp.get('title', '')).fillna('')\n",
    "    tmp['combined_text'] = (tmp['review_title'] + ' ' + tmp['review_text']).str.strip()\n",
    "\n",
    "    tmp['review_length'] = tmp['review_text'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "    if 'images_review' in tmp.columns:\n",
    "        tmp['has_images'] = tmp['images_review'].apply(lambda x: int(isinstance(x, list) and len(x) > 0))\n",
    "    elif 'images' in tmp.columns:\n",
    "        tmp['has_images'] = tmp['images'].apply(lambda x: int(isinstance(x, list) and len(x) > 0))\n",
    "    else:\n",
    "        tmp['has_images'] = 0\n",
    "\n",
    "    tmp['helpful_votes'] = tmp.get('helpful_votes', 0).fillna(0).astype(float)\n",
    "    tmp['rating']        = tmp.get('rating', np.nan).astype(float)\n",
    "    tmp['price']         = tmp.get('price', np.nan).astype(float)\n",
    "    tmp['average_rating']= tmp.get('average_rating', np.nan).astype(float)\n",
    "    tmp['rating_number'] = tmp.get('rating_number', np.nan).astype(float)\n",
    "\n",
    "    tmp['main_category'] = tmp.get('main_category', 'Unknown').fillna('Unknown')\n",
    "    tmp['store']         = tmp.get('store', 'Unknown').fillna('Unknown')\n",
    "\n",
    "    numeric_features = [\n",
    "        'rating',\n",
    "        'helpful_votes',\n",
    "        'review_length',\n",
    "        'has_images',\n",
    "        'price',\n",
    "        'average_rating',\n",
    "        'rating_number',\n",
    "    ]\n",
    "    tmp[numeric_features] = tmp[numeric_features].fillna(tmp[numeric_features].median())\n",
    "\n",
    "    X_all = tmp[['combined_text'] + numeric_features + ['main_category', 'store']]\n",
    "\n",
    "    # predict probabilities of verified\n",
    "    proba_verified = model.predict_proba(X_all)[:, 1]\n",
    "    tmp['prob_verified'] = proba_verified\n",
    "    tmp['suspicious_flag'] = (tmp['prob_verified'] < threshold_verified).astype(int)\n",
    "\n",
    "    # most suspicious = lowest prob_verified\n",
    "    suspicious = tmp.sort_values('prob_verified', ascending=True).head(top_n)\n",
    "\n",
    "    return suspicious[['rating', 'helpful_votes', 'review_text', 'prob_verified', 'suspicious_flag']]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agential",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
