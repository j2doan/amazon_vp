{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b851292e-cb4f-4cec-88bc-ea9d45f907f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    precision_recall_curve,\n",
    "    precision_recall_fscore_support,\n",
    "    make_scorer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf63e45-91a3-4f8a-92eb-a2724eac43ed",
   "metadata": {},
   "source": [
    "# Baseline Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3069915c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/leyufeng/Downloads/amazon_vp/All_Beauty.jsonl.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m reviews_path = \u001b[33m'\u001b[39m\u001b[33m~/Downloads/amazon_vp/All_Beauty.jsonl.gz\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     18\u001b[39m meta_path    = \u001b[33m'\u001b[39m\u001b[33m~/Downloads/amazon_vp/meta_All_Beauty.jsonl.gz\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m df_reviews = \u001b[43mload_jsonl_gz\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreviews_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m df_meta    = load_jsonl_gz(meta_path,    limit=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mReviews shape:\u001b[39m\u001b[33m\"\u001b[39m, df_reviews.shape)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mload_jsonl_gz\u001b[39m\u001b[34m(path, limit)\u001b[39m\n\u001b[32m      2\u001b[39m path = os.path.expanduser(path)\n\u001b[32m      3\u001b[39m rows = []\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mgzip\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(f):\n\u001b[32m      6\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m i >= limit:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/gzip.py:61\u001b[39m, in \u001b[36mopen\u001b[39m\u001b[34m(filename, mode, compresslevel, encoding, errors, newline)\u001b[39m\n\u001b[32m     59\u001b[39m gz_mode = mode.replace(\u001b[33m\"\u001b[39m\u001b[33mt\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filename, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m, os.PathLike)):\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m     binary_file = \u001b[43mGzipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgz_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompresslevel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(filename, \u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(filename, \u001b[33m\"\u001b[39m\u001b[33mwrite\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     63\u001b[39m     binary_file = GzipFile(\u001b[38;5;28;01mNone\u001b[39;00m, gz_mode, compresslevel, filename)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/gzip.py:192\u001b[39m, in \u001b[36mGzipFile.__init__\u001b[39m\u001b[34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[39m\n\u001b[32m    190\u001b[39m     mode += \u001b[33m'\u001b[39m\u001b[33mb\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     fileobj = \u001b[38;5;28mself\u001b[39m.myfileobj = \u001b[43mbuiltins\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    194\u001b[39m     filename = \u001b[38;5;28mgetattr\u001b[39m(fileobj, \u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/Users/leyufeng/Downloads/amazon_vp/All_Beauty.jsonl.gz'"
     ]
    }
   ],
   "source": [
    "def load_jsonl_gz(path, limit=None):\n",
    "    path = os.path.expanduser(path)\n",
    "    rows = []\n",
    "    with gzip.open(path, 'rt', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if limit is not None and i >= limit:\n",
    "                break\n",
    "            try:\n",
    "                rows.append(json.loads(line))\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# DATA LOADING \n",
    "\n",
    "reviews_path = '~/Downloads/amazon_vp/All_Beauty.jsonl.gz'\n",
    "meta_path    = '~/Downloads/amazon_vp/meta_All_Beauty.jsonl.gz'\n",
    "\n",
    "df_reviews = load_jsonl_gz(reviews_path, limit=None)\n",
    "df_meta    = load_jsonl_gz(meta_path,    limit=None)\n",
    "\n",
    "print(\"Reviews shape:\", df_reviews.shape)\n",
    "print(\"Meta shape:\", df_meta.shape)\n",
    "print(\"Review columns:\", df_reviews.columns.tolist())\n",
    "print(\"Meta columns:\", df_meta.columns.tolist())\n",
    "\n",
    "\n",
    "# DATA CLEANING\n",
    "\n",
    "# 'helpful_vote' vs 'helpful_votes'\n",
    "if 'helpful_votes' not in df_reviews.columns and 'helpful_vote' in df_reviews.columns:\n",
    "    df_reviews['helpful_votes'] = df_reviews['helpful_vote']\n",
    "\n",
    "# 'sort_timestamp' vs 'timestamp'\n",
    "if 'sort_timestamp' in df_reviews.columns and 'timestamp' not in df_reviews.columns:\n",
    "    df_reviews['timestamp'] = df_reviews['sort_timestamp']\n",
    "\n",
    "# check verified_purchase exists\n",
    "if 'verified_purchase' not in df_reviews.columns:\n",
    "    raise ValueError(\"verified_purchase column not found in review data.\")\n",
    "\n",
    "# parent_asin vs asin\n",
    "join_key = 'asin'\n",
    "if 'parent_asin' in df_reviews.columns and 'parent_asin' in df_meta.columns:\n",
    "    join_key = 'parent_asin'\n",
    "\n",
    "print(\"Merging on key:\", join_key)\n",
    "\n",
    "df = df_reviews.merge(df_meta, on=join_key, how='left', suffixes=('_review', '_product'))\n",
    "\n",
    "df = df.dropna(subset=['text', 'verified_purchase'])\n",
    "\n",
    "print(\"Merged shape:\", df.shape)\n",
    "\n",
    "\n",
    "# CHECKING FEATURES\n",
    "\n",
    "df['review_text']  = df['text'].fillna('')\n",
    "df['review_title'] = df.get('title_review', df.get('title', '')).fillna('')\n",
    "\n",
    "# title + text\n",
    "df['combined_text'] = (df['review_title'] + ' ' + df['review_text']).str.strip()\n",
    "\n",
    "# review length (in words)\n",
    "df['review_length'] = df['review_text'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# binary: has images in review\n",
    "if 'images_review' in df.columns:\n",
    "    df['has_images'] = df['images_review'].apply(lambda x: int(isinstance(x, list) and len(x) > 0))\n",
    "elif 'images' in df.columns:\n",
    "    df['has_images'] = df['images'].apply(lambda x: int(isinstance(x, list) and len(x) > 0))\n",
    "else:\n",
    "    df['has_images'] = 0\n",
    "\n",
    "# helpful votes\n",
    "if 'helpful_votes' in df.columns:\n",
    "    df['helpful_votes'] = df['helpful_votes'].fillna(0).astype(float)\n",
    "else:\n",
    "    df['helpful_votes'] = 0.0\n",
    "\n",
    "# ratings\n",
    "if 'rating' in df.columns:\n",
    "    df['rating'] = df['rating'].astype(float)\n",
    "else:\n",
    "    df['rating'] = np.nan\n",
    "\n",
    "# product features (num)\n",
    "df['price']          = df.get('price', np.nan).astype(float)\n",
    "df['average_rating'] = df.get('average_rating', np.nan).astype(float)\n",
    "df['rating_number']  = df.get('rating_number', np.nan).astype(float)\n",
    "\n",
    "# product features (cat)\n",
    "df['main_category']  = df.get('main_category', 'Unknown').fillna('Unknown')\n",
    "df['store']          = df.get('store', 'Unknown').fillna('Unknown')\n",
    "\n",
    "y = df['verified_purchase'].astype(int)\n",
    "\n",
    "text_col = 'combined_text'\n",
    "numeric_features = [\n",
    "    'rating',\n",
    "    'helpful_votes',\n",
    "    'review_length',\n",
    "    'has_images',\n",
    "    'price',\n",
    "    'average_rating',\n",
    "    'rating_number',\n",
    "]\n",
    "categorical_features = [\n",
    "    'main_category',\n",
    "    'store',\n",
    "]\n",
    "\n",
    "# missing vals\n",
    "for col in numeric_features:\n",
    "    if col not in df.columns:\n",
    "        df[col] = np.nan\n",
    "df[numeric_features] = df[numeric_features].fillna(df[numeric_features].median())\n",
    "\n",
    "X = df[[text_col] + numeric_features + categorical_features]\n",
    "\n",
    "\n",
    "# split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train size:\", X_train.shape, \"Test size:\", X_test.shape)\n",
    "\n",
    "\n",
    "# text + numeric + categorical -> logistic regression\n",
    "\n",
    "text_transformer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words='english'\n",
    ")\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text', text_transformer, text_col),\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "clf = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    solver='saga',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocess', preprocess),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# TRAINING\n",
    "print(\"Fitting model...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# EVAL\n",
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "\n",
    "\n",
    "# predictor new rev\n",
    "def predict_verified(\n",
    "    review_text,\n",
    "    review_title=\"\",\n",
    "    rating=5.0,\n",
    "    helpful_votes=0,\n",
    "    images_count=0,\n",
    "    price=np.nan,\n",
    "    average_rating=np.nan,\n",
    "    rating_number=np.nan,\n",
    "    main_category=\"All Beauty\",\n",
    "    store=\"Unknown\"\n",
    "):\n",
    "    # is review from verified purchase? \n",
    "    \n",
    "    has_images = int(images_count > 0)\n",
    "    review_length = len(str(review_text).split())\n",
    "\n",
    "    data = pd.DataFrame([{\n",
    "        'combined_text': (review_title + \" \" + review_text).strip(),\n",
    "        'rating': float(rating),\n",
    "        'helpful_votes': float(helpful_votes),\n",
    "        'review_length': review_length,\n",
    "        'has_images': has_images,\n",
    "        'price': price,\n",
    "        'average_rating': average_rating,\n",
    "        'rating_number': rating_number,\n",
    "        'main_category': main_category,\n",
    "        'store': store,\n",
    "    }])\n",
    "\n",
    "    proba = model.predict_proba(data)[0, 1]\n",
    "    pred = model.predict(data)[0]\n",
    "\n",
    "    return {\n",
    "        'predicted_verified_flag': int(pred),\n",
    "        'probability_verified': float(proba)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1c5db5-a0c7-4765-8c9b-c2c55989182c",
   "metadata": {},
   "source": [
    "# Balanced Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf6e8f82",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#    - 'text', 'title_review' or 'title'\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#    - 'verified_purchase'\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#    - 'rating', 'helpful_votes', 'price',\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      6\u001b[39m \n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# text\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mreview_text\u001b[39m\u001b[33m'\u001b[39m]  = \u001b[43mdf\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m].fillna(\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      9\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mreview_title\u001b[39m\u001b[33m'\u001b[39m] = df.get(\u001b[33m'\u001b[39m\u001b[33mtitle_review\u001b[39m\u001b[33m'\u001b[39m, df.get(\u001b[33m'\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)).fillna(\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     10\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mcombined_text\u001b[39m\u001b[33m'\u001b[39m] = (df[\u001b[33m'\u001b[39m\u001b[33mreview_title\u001b[39m\u001b[33m'\u001b[39m] + \u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m + df[\u001b[33m'\u001b[39m\u001b[33mreview_text\u001b[39m\u001b[33m'\u001b[39m]).str.strip()\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#    - 'text', 'title_review' or 'title'\n",
    "#    - 'verified_purchase'\n",
    "#    - 'rating', 'helpful_votes', 'price',\n",
    "#      'average_rating', 'rating_number',\n",
    "#      'main_category', 'store'\n",
    "\n",
    "# text\n",
    "df['review_text']  = df['text'].fillna('')\n",
    "df['review_title'] = df.get('title_review', df.get('title', '')).fillna('')\n",
    "df['combined_text'] = (df['review_title'] + ' ' + df['review_text']).str.strip()\n",
    "\n",
    "# numeric features\n",
    "df['review_length'] = df['review_text'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "if 'images_review' in df.columns:\n",
    "    df['has_images'] = df['images_review'].apply(lambda x: int(isinstance(x, list) and len(x) > 0))\n",
    "elif 'images' in df.columns:\n",
    "    df['has_images'] = df['images'].apply(lambda x: int(isinstance(x, list) and len(x) > 0))\n",
    "else:\n",
    "    df['has_images'] = 0\n",
    "\n",
    "df['helpful_votes'] = df.get('helpful_votes', 0).fillna(0).astype(float)\n",
    "df['rating']        = df.get('rating', np.nan).astype(float)\n",
    "df['price']         = df.get('price', np.nan).astype(float)\n",
    "df['average_rating']= df.get('average_rating', np.nan).astype(float)\n",
    "df['rating_number'] = df.get('rating_number', np.nan).astype(float)\n",
    "\n",
    "df['main_category'] = df.get('main_category', 'Unknown').fillna('Unknown')\n",
    "df['store']         = df.get('store', 'Unknown').fillna('Unknown')\n",
    "\n",
    "y = df['verified_purchase'].astype(int)\n",
    "\n",
    "text_col = 'combined_text'\n",
    "numeric_features = [\n",
    "    'rating',\n",
    "    'helpful_votes',\n",
    "    'review_length',\n",
    "    'has_images',\n",
    "    'price',\n",
    "    'average_rating',\n",
    "    'rating_number',\n",
    "]\n",
    "categorical_features = ['main_category', 'store']\n",
    "\n",
    "# rep na with median\n",
    "df[numeric_features] = df[numeric_features].fillna(df[numeric_features].median())\n",
    "\n",
    "X = df[[text_col] + numeric_features + categorical_features]\n",
    "\n",
    "# train/test stratified split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "text_transformer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words='english'\n",
    ")\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text', text_transformer, text_col),\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# logistic reg \n",
    "clf = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    solver='saga',\n",
    "    n_jobs=-1,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocess', preprocess),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "print(\"Fitting balanced model...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# default thres 0.5\n",
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n=== Balanced Model (Threshold 0.5) ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e5a9bec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     34\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mt = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_t\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, prec=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_stats[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, rec=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_stats[\u001b[32m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, f1=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_stats[\u001b[32m2\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m best_t, best_stats\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m best_t, best_stats = find_best_threshold_for_unverified(\u001b[43my_test\u001b[49m, y_proba)\n",
      "\u001b[31mNameError\u001b[39m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "def find_best_threshold_for_unverified(y_true, y_proba, verbose=True):\n",
    "    best_t = 0.5\n",
    "    best_f1 = -1\n",
    "    best_stats = None\n",
    "\n",
    "    # thresholds over verified probability\n",
    "    thresholds = np.linspace(0.1, 0.9, 17)\n",
    "\n",
    "    for t in thresholds:\n",
    "        # predict verified=1 if proba >= t, else 0\n",
    "        y_pred = (y_proba >= t).astype(int)\n",
    "\n",
    "        # compute precision/recall/f1 per class\n",
    "        prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "            y_true, y_pred, average=None, labels=[0, 1]\n",
    "        )\n",
    "        # index 0 = class 0 (unverified)\n",
    "        f1_unverified = f1[0]\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Threshold {t:.2f} → class 0 (unverified) F1 = {f1_unverified:.3f}, \"\n",
    "                  f\"prec={prec[0]:.3f}, rec={rec[0]:.3f}\")\n",
    "\n",
    "        if f1_unverified > best_f1:\n",
    "            best_f1 = f1_unverified\n",
    "            best_t = t\n",
    "            best_stats = (prec[0], rec[0], f1_unverified)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\nBest threshold for unverified:\")\n",
    "        print(f\"t = {best_t:.2f}, prec={best_stats[0]:.3f}, rec={best_stats[1]:.3f}, f1={best_stats[2]:.3f}\")\n",
    "\n",
    "    return best_t, best_stats\n",
    "\n",
    "best_t, best_stats = find_best_threshold_for_unverified(y_test, y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0fe8ac89",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# FIXING MODEL B\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mreview_text\u001b[39m\u001b[33m'\u001b[39m]  = \u001b[43mdf\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m].fillna(\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mreview_title\u001b[39m\u001b[33m'\u001b[39m] = df.get(\u001b[33m'\u001b[39m\u001b[33mtitle_review\u001b[39m\u001b[33m'\u001b[39m, df.get(\u001b[33m'\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)).fillna(\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mcombined_text\u001b[39m\u001b[33m'\u001b[39m] = (df[\u001b[33m'\u001b[39m\u001b[33mreview_title\u001b[39m\u001b[33m'\u001b[39m] + \u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m + df[\u001b[33m'\u001b[39m\u001b[33mreview_text\u001b[39m\u001b[33m'\u001b[39m]).str.strip()\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# FIXING MODEL B\n",
    "\n",
    "df['review_text']  = df['text'].fillna('')\n",
    "df['review_title'] = df.get('title_review', df.get('title', '')).fillna('')\n",
    "df['combined_text'] = (df['review_title'] + ' ' + df['review_text']).str.strip()\n",
    "\n",
    "df['review_length'] = df['review_text'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "if 'images_review' in df.columns:\n",
    "    df['has_images'] = df['images_review'].apply(\n",
    "        lambda x: int(isinstance(x, list) and len(x) > 0)\n",
    "    )\n",
    "elif 'images' in df.columns:\n",
    "    df['has_images'] = df['images'].apply(\n",
    "        lambda x: int(isinstance(x, list) and len(x) > 0)\n",
    "    )\n",
    "else:\n",
    "    df['has_images'] = 0\n",
    "\n",
    "df['helpful_votes']  = df.get('helpful_votes', 0).fillna(0).astype(float)\n",
    "df['rating']         = df.get('rating', np.nan).astype(float)\n",
    "df['price']          = df.get('price', np.nan).astype(float)\n",
    "df['average_rating'] = df.get('average_rating', np.nan).astype(float)\n",
    "df['rating_number']  = df.get('rating_number', np.nan).astype(float)\n",
    "\n",
    "df['main_category']  = df.get('main_category', 'Unknown').fillna('Unknown')\n",
    "df['store']          = df.get('store', 'Unknown').fillna('Unknown')\n",
    "\n",
    "# label: 1 = verified, 0 = unverified\n",
    "y = df['verified_purchase'].astype(int)\n",
    "\n",
    "text_col = 'combined_text'\n",
    "numeric_features = [\n",
    "    'rating',\n",
    "    'helpful_votes',\n",
    "    'review_length',\n",
    "    'has_images',\n",
    "    'price',\n",
    "    'average_rating',\n",
    "    'rating_number',\n",
    "]\n",
    "categorical_features = ['main_category', 'store']\n",
    "\n",
    "df[numeric_features] = df[numeric_features].fillna(df[numeric_features].median())\n",
    "\n",
    "X = df[[text_col] + numeric_features + categorical_features]\n",
    "\n",
    "# split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# preprocessing\n",
    "text_transformer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words='english'\n",
    ")\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text', text_transformer, text_col),\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "clf = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    solver='saga',\n",
    "    n_jobs=-1,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocess', preprocess),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "print(\"Fitting balanced model...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_proba_verified = model.predict_proba(X_test)[:, 1]\n",
    "y_pred_default = (y_proba_verified >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\n=== Balanced Model (Threshold 0.5) ===\")\n",
    "print(classification_report(y_test, y_pred_default))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba_verified))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred_default))\n",
    "\n",
    "# threshold tuning\n",
    "\n",
    "proba_unverified = 1 - y_proba_verified\n",
    "\n",
    "precision0, recall0, thresholds = precision_recall_curve(\n",
    "    y_test,\n",
    "    proba_unverified,\n",
    "    pos_label=0\n",
    ")\n",
    "\n",
    "f1_0 = 2 * precision0 * recall0 / (precision0 + recall0 + 1e-12)\n",
    "\n",
    "# choose best recall\n",
    "\n",
    "target_precision0 = 0.60\n",
    "valid_idxs = np.where(precision0 >= target_precision0)[0]\n",
    "\n",
    "if len(valid_idxs) > 0:\n",
    "    best_idx = valid_idxs[recall0[valid_idxs].argmax()]\n",
    "    strategy = f\"precision0 >= {target_precision0}\"\n",
    "else:\n",
    "    best_idx = f1_0.argmax()\n",
    "    strategy = \"max F1 for class 0 (fallback)\"\n",
    "\n",
    "best_thresh_unverified = thresholds[best_idx]\n",
    "best_thresh_verified   = 1.0 - best_thresh_unverified\n",
    "\n",
    "print(\"\\n=== Tuned threshold for unverified (class 0) ===\")\n",
    "print(f\"Selection strategy: {strategy}\")\n",
    "print(f\"Threshold on P(unverified): {best_thresh_unverified:.3f}\")\n",
    "print(f\"Threshold on P(verified)  : {best_thresh_verified:.3f}\")\n",
    "print(f\"precision0={precision0[best_idx]:.3f}, recall0={recall0[best_idx]:.3f}, f1_0={f1_0[best_idx]:.3f}\")\n",
    "\n",
    "\n",
    "y_pred_tuned = (y_proba_verified >= best_thresh_verified).astype(int)\n",
    "\n",
    "print(\"\\n=== Balanced Model with Tuned Threshold (better for unverified) ===\")\n",
    "print(classification_report(y_test, y_pred_tuned))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred_tuned))\n",
    "print(\"ROC-AUC (unchanged):\", roc_auc_score(y_test, y_proba_verified))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8d1dbd-146f-4428-b20b-f3c9805061f3",
   "metadata": {},
   "source": [
    "# Final Model: Tuned Logistic Regression (GridSearchCV + Threshold Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78bc2b9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     11\u001b[39m     classification_report,\n\u001b[32m     12\u001b[39m     roc_auc_score,\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     make_scorer\n\u001b[32m     16\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mreview_text\u001b[39m\u001b[33m'\u001b[39m]  = \u001b[43mdf\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m].fillna(\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     19\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mreview_title\u001b[39m\u001b[33m'\u001b[39m] = df.get(\u001b[33m'\u001b[39m\u001b[33mtitle_review\u001b[39m\u001b[33m'\u001b[39m, df.get(\u001b[33m'\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)).fillna(\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     20\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mcombined_text\u001b[39m\u001b[33m'\u001b[39m] = (df[\u001b[33m'\u001b[39m\u001b[33mreview_title\u001b[39m\u001b[33m'\u001b[39m] + \u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m + df[\u001b[33m'\u001b[39m\u001b[33mreview_text\u001b[39m\u001b[33m'\u001b[39m]).str.strip()\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df['review_text']  = df['text'].fillna('')\n",
    "df['review_title'] = df.get('title_review', df.get('title', '')).fillna('')\n",
    "df['combined_text'] = (df['review_title'] + ' ' + df['review_text']).str.strip()\n",
    "\n",
    "df['review_length'] = df['review_text'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "if 'images_review' in df.columns:\n",
    "    df['has_images'] = df['images_review'].apply(\n",
    "        lambda x: int(isinstance(x, list) and len(x) > 0)\n",
    "    )\n",
    "elif 'images' in df.columns:\n",
    "    df['has_images'] = df['images'].apply(\n",
    "        lambda x: int(isinstance(x, list) and len(x) > 0)\n",
    "    )\n",
    "else:\n",
    "    df['has_images'] = 0\n",
    "\n",
    "df['helpful_votes']  = df.get('helpful_votes', 0).fillna(0).astype(float)\n",
    "df['rating']         = df.get('rating', np.nan).astype(float)\n",
    "df['price']          = df.get('price', np.nan).astype(float)\n",
    "df['average_rating'] = df.get('average_rating', np.nan).astype(float)\n",
    "df['rating_number']  = df.get('rating_number', np.nan).astype(float)\n",
    "\n",
    "df['main_category']  = df.get('main_category', 'Unknown').fillna('Unknown')\n",
    "df['store']          = df.get('store', 'Unknown').fillna('Unknown')\n",
    "\n",
    "y = df['verified_purchase'].astype(int)\n",
    "\n",
    "text_col = 'combined_text'\n",
    "numeric_features = [\n",
    "    'rating',\n",
    "    'helpful_votes',\n",
    "    'review_length',\n",
    "    'has_images',\n",
    "    'price',\n",
    "    'average_rating',\n",
    "    'rating_number',\n",
    "]\n",
    "categorical_features = ['main_category', 'store']\n",
    "\n",
    "df[numeric_features] = df[numeric_features].fillna(df[numeric_features].median())\n",
    "X = df[[text_col] + numeric_features + categorical_features]\n",
    "\n",
    "# split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# preprocessing\n",
    "\n",
    "text_transformer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words='english'\n",
    ")\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text', text_transformer, text_col),\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "base_clf = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    solver='saga',\n",
    "    n_jobs=-1,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    ('preprocess', preprocess),\n",
    "    ('clf', base_clf)\n",
    "])\n",
    "\n",
    "# hyperparam tuning\n",
    "\n",
    "def f1_class0(y_true, y_pred):\n",
    "    from sklearn.metrics import f1_score\n",
    "    return f1_score(y_true, y_pred, pos_label=0)\n",
    "\n",
    "scorer = make_scorer(f1_class0)\n",
    "\n",
    "param_grid = {\n",
    "    'clf__C': [0.1, 0.5, 1.0, 2.0, 5.0]\n",
    "}\n",
    "\n",
    "print(\"Fitting tuned logistic regression with CV...\")\n",
    "grid = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scorer,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best C from CV:\", grid.best_params_)\n",
    "\n",
    "model = grid.best_estimator_\n",
    "\n",
    "# threshold 0.5\n",
    "\n",
    "y_proba_verified = model.predict_proba(X_test)[:, 1]\n",
    "y_pred_default = (y_proba_verified >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\n=== Tuned Logistic (Threshold 0.5) ===\")\n",
    "print(classification_report(y_test, y_pred_default))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba_verified))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred_default))\n",
    "\n",
    "\n",
    "proba_unverified = 1 - y_proba_verified\n",
    "\n",
    "precision0, recall0, thresholds = precision_recall_curve(\n",
    "    y_test,\n",
    "    proba_unverified,\n",
    "    pos_label=0\n",
    ")\n",
    "\n",
    "f1_0 = 2 * precision0 * recall0 / (precision0 + recall0 + 1e-12)\n",
    "best_idx = f1_0.argmax()\n",
    "\n",
    "best_thresh_unverified = thresholds[best_idx]\n",
    "best_thresh_verified   = 1.0 - best_thresh_unverified\n",
    "\n",
    "print(\"\\n=== Best F1 point for class 0 (unverified) ===\")\n",
    "print(f\"Threshold on P(unverified): {best_thresh_unverified:.3f}\")\n",
    "print(f\"Threshold on P(verified)  : {best_thresh_verified:.3f}\")\n",
    "print(f\"precision0={precision0[best_idx]:.3f}, recall0={recall0[best_idx]:.3f}, f1_0={f1_0[best_idx]:.3f}\")\n",
    "\n",
    "y_pred_tuned = (y_proba_verified >= best_thresh_verified).astype(int)\n",
    "\n",
    "print(\"\\n=== Tuned Logistic + Tuned Threshold (good balance for unverified) ===\")\n",
    "print(classification_report(y_test, y_pred_tuned))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred_tuned))\n",
    "print(\"ROC-AUC (unchanged):\", roc_auc_score(y_test, y_proba_verified))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98cdc72-ba96-45be-acc2-682736d64cb5",
   "metadata": {},
   "source": [
    "### Helper function to flag suspicious reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20f81ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_suspicious_reviews(df_reviews_raw, model, threshold_verified=0.7, top_n=50):\n",
    "    tmp = df_reviews_raw.copy()\n",
    "\n",
    "    tmp['review_text']  = tmp['text'].fillna('')\n",
    "    tmp['review_title'] = tmp.get('title_review', tmp.get('title', '')).fillna('')\n",
    "    tmp['combined_text'] = (tmp['review_title'] + ' ' + tmp['review_text']).str.strip()\n",
    "\n",
    "    tmp['review_length'] = tmp['review_text'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "    if 'images_review' in tmp.columns:\n",
    "        tmp['has_images'] = tmp['images_review'].apply(lambda x: int(isinstance(x, list) and len(x) > 0))\n",
    "    elif 'images' in tmp.columns:\n",
    "        tmp['has_images'] = tmp['images'].apply(lambda x: int(isinstance(x, list) and len(x) > 0))\n",
    "    else:\n",
    "        tmp['has_images'] = 0\n",
    "\n",
    "    tmp['helpful_votes'] = tmp.get('helpful_votes', 0).fillna(0).astype(float)\n",
    "    tmp['rating']        = tmp.get('rating', np.nan).astype(float)\n",
    "    tmp['price']         = tmp.get('price', np.nan).astype(float)\n",
    "    tmp['average_rating']= tmp.get('average_rating', np.nan).astype(float)\n",
    "    tmp['rating_number'] = tmp.get('rating_number', np.nan).astype(float)\n",
    "\n",
    "    tmp['main_category'] = tmp.get('main_category', 'Unknown').fillna('Unknown')\n",
    "    tmp['store']         = tmp.get('store', 'Unknown').fillna('Unknown')\n",
    "\n",
    "    numeric_features = [\n",
    "        'rating',\n",
    "        'helpful_votes',\n",
    "        'review_length',\n",
    "        'has_images',\n",
    "        'price',\n",
    "        'average_rating',\n",
    "        'rating_number',\n",
    "    ]\n",
    "    tmp[numeric_features] = tmp[numeric_features].fillna(tmp[numeric_features].median())\n",
    "\n",
    "    X_all = tmp[['combined_text'] + numeric_features + ['main_category', 'store']]\n",
    "\n",
    "    # predict probabilities of verified\n",
    "    proba_verified = model.predict_proba(X_all)[:, 1]\n",
    "    tmp['prob_verified'] = proba_verified\n",
    "    tmp['suspicious_flag'] = (tmp['prob_verified'] < threshold_verified).astype(int)\n",
    "\n",
    "    # most suspicious = lowest prob_verified\n",
    "    suspicious = tmp.sort_values('prob_verified', ascending=True).head(top_n)\n",
    "\n",
    "    return suspicious[['rating', 'helpful_votes', 'review_text', 'prob_verified', 'suspicious_flag']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0c0322-57e8-421a-a2e4-281993dc1433",
   "metadata": {},
   "source": [
    "### Final evaluation on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d8bd0c-0cbd-44b2-8a57-4fa992e91da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "print(\"ROC-AUC:\", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013f81c2-8c7e-43f6-94c4-9a12aed3599c",
   "metadata": {},
   "source": [
    "### Precision-recall curve plot for unverified reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56140848",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'recall0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      3\u001b[39m plt.figure(figsize=(\u001b[32m6\u001b[39m, \u001b[32m5\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m plt.plot(\u001b[43mrecall0\u001b[49m, precision0, label=\u001b[33m\"\u001b[39m\u001b[33mPR curve (class 0)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m plt.scatter(\n\u001b[32m      6\u001b[39m     recall0[best_idx],\n\u001b[32m      7\u001b[39m     precision0[best_idx],\n\u001b[32m      8\u001b[39m     color=\u001b[33m\"\u001b[39m\u001b[33mred\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      9\u001b[39m     label=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mchosen threshold (F1₀ = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1_0[best_idx]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     10\u001b[39m )\n\u001b[32m     11\u001b[39m plt.xlabel(\u001b[33m\"\u001b[39m\u001b[33mRecall (unverified)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'recall0' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(recall0, precision0, label=\"PR curve (class 0)\")\n",
    "plt.scatter(\n",
    "    recall0[best_idx],\n",
    "    precision0[best_idx],\n",
    "    color=\"red\",\n",
    "    label=f\"chosen threshold (F1₀ = {f1_0[best_idx]:.3f})\"\n",
    ")\n",
    "plt.xlabel(\"Recall (unverified)\")\n",
    "plt.ylabel(\"Precision (unverified)\")\n",
    "plt.title(\"Precision–Recall Curve for Unverified Reviews\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.grid(True)\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
